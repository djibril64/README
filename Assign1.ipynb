{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Assign1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoLyFQ0ZYpfzBzJIvs/vYd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djibril64/README/blob/main/Assign1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj_vOjSa-G-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508553cf-6efd-4ebe-e3c7-98a2441a02ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdZ9ZWJtR2em"
      },
      "source": [
        "!unzip /content/drive/MyDrive/face-expression-recognition-dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42sXUbJxlLoe"
      },
      "source": [
        "!pip install keras\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZewvlLF7BsLW"
      },
      "source": [
        "# This will display some images for every different expression\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# size of the image: 48*48 pixels\n",
        "pic_size = 48\n",
        "\n",
        "# input path for the images\n",
        "base_path = \"../content/drive/MyDrive/face-expression-recognition-dataset/images/images/\"\n",
        "\n",
        "plt.figure(0, figsize=(12,20))\n",
        "cpt = 0\n",
        "\n",
        "for expression in os.listdir(base_path + \"train/\"):\n",
        "    for i in range(1,6):\n",
        "        cpt = cpt + 1\n",
        "        plt.subplot(7,5,cpt)\n",
        "        img = load_img(base_path + \"train/\" + expression + \"/\" +os.listdir(base_path + \"train/\" + expression)[i], target_size=(pic_size, pic_size))\n",
        "        plt.imshow(img, cmap=\"gray\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz-J6A2jYKhu"
      },
      "source": [
        "GDRIVEPATH='/content/drive/MyDrive/face-expression-recognition-dataset/images/images'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExQe79QbXduB"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.compat.v1.keras import backend as K\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "base_dir = GDRIVEPATH\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "\n",
        "#Training class folder for disgust, happy, surprise, sad, and angry. \n",
        "train_disgust_dir = os.path.join(train_dir, 'disgust')          \n",
        "train_happy_dir = os.path.join(train_dir, 'happy')              \n",
        "train_surprise_dir = os.path.join(train_dir, 'surprise')        \n",
        "train_sad_dir = os.path.join(train_dir, 'sad')                  \n",
        "train_angry_dir = os.path.join(train_dir, 'angry')              \n",
        "\n",
        "#Validation class folder for disgust, happy, surprise, sad, and angry. \n",
        "validation_disgust_dir = os.path.join(validation_dir, 'disgust')            \n",
        "validation_happy_dir = os.path.join(validation_dir, 'happy')                \n",
        "validation_surprise_dir = os.path.join(validation_dir, 'surprise')          \n",
        "validation_sad_dir = os.path.join(validation_dir, 'sad')                   \n",
        "validation_angry_dir = os.path.join(validation_dir, 'angry')                \n",
        "\n",
        "#Testing class folder for disgust, happy, surprise, sad, and angry. \n",
        "test_disgust_dir = os.path.join(test_dir, 'disgust')                          \n",
        "test_happy_dir = os.path.join(test_dir, 'happy')                  \n",
        "test_surprise_dir = os.path.join(test_dir, 'surprise')            \n",
        "test_sad_dir = os.path.join(test_dir, 'sad')                     \n",
        "test_angry_dir = os.path.join(test_dir, 'angry')                  \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxhzDeCCDi3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07fbdff3-7392-40d6-8b40-5a3d78c21c3f"
      },
      "source": [
        "#This is to print training label for disgust, happy, surprise, sad, and angry. \n",
        "print('Total training disgust images:', len(os.listdir(train_disgust_dir)))      \n",
        "print('Total training happy images:', len(os.listdir(train_happy_dir)))          \n",
        "print('Total training surprise images:', len(os.listdir(train_surprise_dir)))    \n",
        "print('Total training sad images:', len(os.listdir(train_sad_dir)))              \n",
        "print('Total training angry images:', len(os.listdir(train_angry_dir)))          \n",
        "\n",
        "\n",
        "#This is to print validation label for disgust, happy, surprise, sad, and angry.           \n",
        "print('Total validation  disgust images:', len(os.listdir(validation_disgust_dir)))     \n",
        "print('Total validation  happy images:', len(os.listdir(validation_happy_dir)))         \n",
        "print('Total validation  surprise images:', len(os.listdir(validation_surprise_dir)))   \n",
        "print('Total validation  sad images:', len(os.listdir(validation_surprise_dir)))   \n",
        "print('Total validation  angry images:', len(os.listdir(validation_angry_dir)))       \n",
        "\n",
        "\n",
        "#This is to print testing label for disgust, happy, surprise, sad, and angry. \n",
        "print('Total test  disgust images:', len(os.listdir(test_disgust_dir)))       \n",
        "print('Total test  happy images:', len(os.listdir(test_happy_dir)))         \n",
        "print('Total test suprise images:', len(os.listdir(test_surprise_dir)))           \n",
        "print('Total test sad images:', len(os.listdir(test_sad_dir)))    \n",
        "print('Total test angry images:', len(os.listdir(test_angry_dir)))        \n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training disgust images: 436\n",
            "Total training happy images: 7164\n",
            "Total training surprise images: 3205\n",
            "Total training sad images: 4938\n",
            "Total training angry images: 3993\n",
            "Total validation  disgust images: 111\n",
            "Total validation  happy images: 1825\n",
            "Total validation  surprise images: 797\n",
            "Total validation  sad images: 797\n",
            "Total validation  angry images: 960\n",
            "Total test  disgust images: 111\n",
            "Total test  happy images: 1835\n",
            "Total test suprise images: 797\n",
            "Total test sad images: 1139\n",
            "Total test angry images: 960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Eaa330AkzK"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "input_shape=(48, 48, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (2, 2), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(512, (2, 2), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "metrics=['acc'])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "121yY8Ac-R-u"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eopt1W29_rY_"
      },
      "source": [
        "GDRIVEPATH='/content/drive/MyDrive/face-expression-recognition-dataset/images/images'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KcnWCSVVMNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2ebc9f-a161-4733-a5bf-7c3a9f5e22f1"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(48, 48),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical',\n",
        "        color_mode= 'grayscale')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(48, 48),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical',\n",
        "        color_mode= 'grayscale')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28821 images belonging to 7 classes.\n",
            "Found 7066 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUvD5zAHphDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d5b665-2af3-4ab9-fdf8-2a16b3147078"
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "     print('data batch shape:', data_batch.shape)\n",
        "     print('labels batch shape:', labels_batch.shape)\n",
        "     break\n",
        "     "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data batch shape: (64, 48, 48, 1)\n",
            "labels batch shape: (64, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNCua0v8Gqxs"
      },
      "source": [
        "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# number of possible label values\n",
        "nb_classes = 5\n",
        "\n",
        "# Initialising the CNN\n",
        "model = Sequential()\n",
        "\n",
        "# 1 - Convolution\n",
        "model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 2nd Convolution layer\n",
        "model.add(Conv2D(128,(5,5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 3rd Convolution layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 4th Convolution layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhWxmcbyDtLO"
      },
      "source": [
        "# number of epochs to train the NN\n",
        "epochs = 500\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                                steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "                                epochs=epochs,\n",
        "                                validation_data = validation_generator,\n",
        "                                validation_steps = validation_generator.n//validation_generator.batch_size,\n",
        "                                callbacks=callbacks_list\n",
        "                                )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9_njjQ7Cmh4"
      },
      "source": [
        "# number of epochs to train the NN\n",
        "epochs = 500\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                                steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "                                epochs=epochs,\n",
        "                                validation_data = validation_generator,\n",
        "                                validation_steps = validation_generator.n//validation_generator.batch_size,\n",
        "                                callbacks=callbacks_list\n",
        "                                )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi-l4-BZkCwY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}